{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPProxyAuth\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Cyber Hymnal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# auth = HTTPProxyAuth(\"username\", \"password\")\n",
    "user_agent_list = ['Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "                   'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36',\n",
    "                   'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36',\n",
    "                   'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1623.0 Safari/537.36',\n",
    "                   'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 7.0; InfoPath.3; .NET CLR 3.1.40767; Trident/6.0; en-IN)',\n",
    "                   'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0'\n",
    "                  ]\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "  rand_user_agent = randint(0,len(user_agent_list)-1)\n",
    "  headers['User-Agent'] = user_agent_list[rand_user_agent]\n",
    "  print(headers['User-Agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.whoishostingthis.com/tools/user-agent/'\n",
    "response = requests.get(url, headers=headers,auth=auth)\n",
    "data = response.text\n",
    "soup = BeautifulSoup(data,\"lxml\")\n",
    "useragent = soup.find(attrs={\"class\":\"info-box user-agent\"})\n",
    "ip = soup.find(attrs={\"class\":\"info-box ip\"})\n",
    "print(useragent.text)\n",
    "print(headers[\"User-Agent\"])\n",
    "print(ip.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Example Code for using Sessions\n",
    "# s = requests.Session()\n",
    "# s.get(url,headers=headers)\n",
    "# print(s.cookies)\n",
    "# r = s.post(url, data=payload,auth=auth,headers=headers,cookies=cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cookie = {'session_name':'session','cookie_1': 'cookie_session_1'}\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "           'header_2':'header_value_2'\n",
    "          }\n",
    "\n",
    "\n",
    "payload = {'input1':'value1',\n",
    "           'input2': 'value2',\n",
    "          }\n",
    "\n",
    "r = requests.post(url, data=payload,auth=auth,headers=headers,cookies=cookie)\n",
    "\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data,\"lxml\")\n",
    "#Debug\n",
    "r.request.headers\n",
    "r.headers\n",
    "\n",
    "file = open(\"output.html\",\"w\") \n",
    "file.write(soup.prettify()) \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create SQLite\n",
    "conn = sqlite3.connect('lyrics.db')\n",
    "eumo = pd.read_csv('EU_MO.csv')\n",
    "eumo.to_sql('test',conn,if_exists='replace')\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute('delete from test')\n",
    "conn.commit\n",
    "\n",
    "pd.read_sql_query(\"select * from test;\",conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap AZ Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Company Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randint\n",
    "#Websites\n",
    "#https://www.sgpbusiness.com\n",
    "\n",
    "#Read up <site>/robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_url = \"http://www.yelu.sg/category/postal-services/\"\n",
    "base_url = \"http://www.yelu.sg\"\n",
    "\n",
    "html = urlopen(search_url)\n",
    "bsObj = BeautifulSoup(html.read(),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "page = bsObj.findAll(\"a\",{\"class\":\"page_no\"})\n",
    "\n",
    "max = 0 \n",
    "for i in page:\n",
    "    page_no = int(i.get_text())\n",
    "    if (page_no > max):\n",
    "        max = page_no\n",
    "print(max)\n",
    "# page.findAll(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.yelu.sg/category/postal-services/1\n",
      "http://www.yelu.sg/category/postal-services/2\n",
      "http://www.yelu.sg/category/postal-services/3\n",
      "http://www.yelu.sg/category/postal-services/4\n",
      "http://www.yelu.sg/category/postal-services/5"
     ]
    }
   ],
   "source": [
    "f1 = open('scrap.txt','w')\n",
    "for x in range(1,max+1):\n",
    "    pg_search = search_url+str(x)\n",
    "    print(search_url+str(x))\n",
    "    #Loop through the pages\n",
    "    pg_url = urlopen(pg_search)\n",
    "    pgObj = BeautifulSoup(pg_url.read(),\"lxml\")\n",
    "    time.sleep(5)\n",
    "    pages = pgObj.findAll(\"h4\")\n",
    "    #Loop through the link in each page\n",
    "    for i in pages:\n",
    "        ref = i.a.get(\"href\")\n",
    "        ran_sleep = randint(10,12)\n",
    "        time.sleep(ran_sleep)\n",
    "        coy = urlopen(base_url+ref)\n",
    "        coyObj = BeautifulSoup(coy.read(),\"lxml\")\n",
    "        for s in scrapitem:\n",
    "          try:\n",
    "            if len(s.find_all('div')) == 0 :\n",
    "              header = s.find('span').get_text()\n",
    "              description = s.get_text()[len(header):]\n",
    "            else: \n",
    "              header = s.find_all('div')[0].get_text()  \n",
    "              if s.find('span') == None :\n",
    "                description = s.find_all('div')[1].get_text()\n",
    "              else : \n",
    "                description = s.find('span').get_text()    \n",
    "            #f1.write(base_url+ref)\n",
    "            f1.write(header,\":\",description,\"\\n\")\n",
    "            if header == 'E-mail' :\n",
    "                break\n",
    "          except AttributeError as e:\n",
    "            continue\n",
    "          except Exception as ea:\n",
    "            continue\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Span\n"
     ]
    }
   ],
   "source": [
    "# t.find_all('div')[0].get_text()\n",
    "# t.find_all('div')[1].get_text()\n",
    "x = t.find('span')\n",
    "if (x == None):\n",
    "  print(\"No Span\")\n",
    "else :\n",
    "  print(\"Yes\")\n",
    "# t.div.find_next_siblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pg_url = urlopen(\"http://www.yelu.sg/category/postal-services/9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgObj = BeautifulSoup(pg_url.read(),\"lxml\")\n",
    "pages = pgObj.findAll(\"h4\")\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read())\n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
